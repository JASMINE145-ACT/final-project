import kagglehub
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from collections import Counter
from tqdm import tqdm
import torch
from sklearn.metrics import accuracy_score, classification_report
from transformers import AutoImageProcessor, AutoModelForImageClassification
from torchvision.transforms import ToPILImage
from torchvision.datasets import ImageFolder
import random
from torch.utils.data import Subset
# Download latest version
path = kagglehub.dataset_download("msambare/fer2013")
print("Path to dataset files:", path)

dataset_path = r"C:\Users\m1774\.cache\kagglehub\datasets\msambare\fer2013\versions\1"
#Compose æ˜¯ ç»„åˆå¤šä¸ªå›¾åƒé¢„å¤„ç†æ­¥éª¤ çš„å·¥å…· å®ƒä¼šæŠŠæ‹¬å·é‡Œçš„æ‰€æœ‰å˜æ¢ æŒ‰é¡ºåºä¸€ä¸ªä¸ªåº”ç”¨åˆ°å›¾åƒä¸Šã€‚
#åŸå§‹å›¾åƒï¼ˆPILï¼‰æ˜¯ 48 x 48ï¼Œæ¯ä¸ªåƒç´ æ˜¯ 0~255 çš„æ•´æ•°ã€‚ç”¨ ToTensor() åï¼Œä¼šå˜æˆ PyTorch å¼ é‡ï¼Œshape æ˜¯ (1, 48, 48)ï¼Œæ¯ä¸ªåƒç´ æ˜¯ 0~1 çš„å°æ•°ã€‚
processor = AutoImageProcessor.from_pretrained("trpakov/vit-face-expression")
perturbation_transform = transforms.Compose([
    transforms.GaussianBlur(3),
    transforms.ColorJitter(brightness=0.3),
])
class CustomDatasetWithProcessor(ImageFolder):
    def __init__(self, root, perturb_transform=None, processor=None):
        super().__init__(root)
        self.perturb_transform = perturb_transform
        self.processor = processor

# æ”¹å†™ __getitem__ï¼šåªè¿”å›æ‰°åŠ¨åçš„ PIL å›¾åƒ
    def __getitem__(self, index):
        path, label = self.samples[index]
        image = self.loader(path)
        if self.perturb_transform:
            image = self.perturb_transform(image)
        return image, label  # ä¸å†æå‰åš processor


train_dataset = CustomDatasetWithProcessor(
    root=dataset_path + "/train",
    perturb_transform=perturbation_transform,
    processor=processor
)
test_dataset = CustomDatasetWithProcessor(
    root=dataset_path + "/test",
    perturb_transform=perturbation_transform,  # ä¹Ÿå¯ä¸åŠ æ‰°åŠ¨
    processor=processor
)
train_indices = list(range(len(train_dataset)))
random.shuffle(train_indices)
small_train_dataset = Subset(train_dataset, train_indices[:len(train_indices)//10])
#transform=...ï¼šå¯¹æ¯å¼ å›¾ç‰‡åº”ç”¨çš„é¢„å¤„ç†æ“ä½œï¼ˆå¦‚ ToTensor() ç­‰ï¼‰
train_loader = DataLoader(small_train_dataset, batch_size=64, shuffle=True,collate_fn=lambda batch: tuple(zip(*batch)))
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False,collate_fn=lambda batch: tuple(zip(*batch)))
#æŠŠæ•°æ®é›†è£…åˆ°ä¸€ä¸ªâ€œæ•°æ®æ‰¹å‘å•†â€é‡Œï¼Œè®­ç»ƒçš„æ—¶å€™æŒ‰ 64 ä¸ªä¸€ç»„é€è¿‡æ¥ã€‚è®­ç»ƒæ—¶æ‰“ä¹±é¡ºåºï¼Œæµ‹è¯•æ—¶æŒ‰é¡ºåºã€‚
print("è®­ç»ƒé›†ä¸­ç±»åˆ«ï¼š", train_dataset.classes)
label_counts = Counter(train_dataset.targets)
#train_dataset.targets æ˜¯ä¸€ä¸ª æ ‡ç­¾åˆ—è¡¨ï¼Œå½¢å¦‚ [3, 0, 1, 2, 3, 0, 3, ...]ï¼Œè¡¨ç¤ºæ¯å¼ å›¾å¯¹åº”çš„æƒ…ç»ªç±»åˆ«ç¼–å·ã€‚
#Counter(...) ä¼šè¿”å›ä¸€ä¸ªå­—å…¸ç»“æ„ï¼Œç»Ÿè®¡æ¯ä¸ªç±»åˆ«ç¼–å·å‡ºç°äº†å¤šå°‘æ¬¡ã€‚
print("è®­ç»ƒé›†ä¸­å„ç±»æ ·æœ¬æ•°ï¼š")
for label, count in label_counts.items():
    print(f"ç±» {label}: {count} å¼ å›¾åƒ")
print(test_dataset.class_to_idx)
import os
model_path = r"C:\Users\m1774\Desktop\507\my_finetuned_model"
# å¦‚æœç›®å½•ä¸å­˜åœ¨å°±åˆ›å»ºå®ƒ
os.makedirs(model_path, exist_ok=True)
if os.path.exists(model_path):
    print("ğŸ“¦ å‘ç°å·²æœ‰ fine-tuned æ¨¡å‹ï¼Œç›´æ¥åŠ è½½è·³è¿‡è®­ç»ƒ")
    model = AutoModelForImageClassification.from_pretrained(model_path,local_files_only=True)
    processor = AutoImageProcessor.from_pretrained(model_path,local_files_only=True)
else:
    processor = AutoImageProcessor.from_pretrained("trpakov/vit-face-expression")
    model = AutoModelForImageClassification.from_pretrained("trpakov/vit-face-expression")
# åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)
criterion = nn.CrossEntropyLoss()
# Fine-tune
num_epochs = 3
for epoch in range(num_epochs):
    model.train()
    total_loss = 0

    for images, labels in tqdm(train_loader, desc=f"Training Epoch {epoch+1}"):
        # 1. è½¬æˆ RGB PIL
        pil_batch = [img.convert("RGB") for img in images]

        # 2. Processor å¤„ç†
        inputs = processor(images=pil_batch, return_tensors="pt", padding=True).to(device)
        labels = torch.tensor(labels).to(device)

        # 3. å‰å‘ + loss
        outputs = model(**inputs)
        loss = criterion(outputs.logits, labels)

        # 4. æ›´æ–°å‚æ•°
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
    print(f"Epoch {epoch+1} | Avg Loss: {total_loss / len(train_loader):.4f}")
if epoch == num_epochs - 1:
    model.save_pretrained(model_path)
    processor.save_pretrained(model_path)  # ä¿å­˜å¤„ç†å™¨ä¸€èµ·ç”¨

model.eval()
to_pil = ToPILImage()
y_true, y_pred = [], []

print(">>> å¼€å§‹ batch æ¨ç†...")

for batch_imgs, batch_labels in tqdm(test_loader, desc="Batch inference"):
    # 1. æŠŠ Tensor å›¾åƒè½¬æ¢æˆ RGB PILï¼ˆåˆ—è¡¨ï¼‰
    pil_batch = [img.convert("RGB") for img in batch_imgs]

    # 2. ç”¨ Hugging Face çš„ processor åš batch å¤„ç†
    inputs = processor(images=pil_batch, return_tensors="pt").to(device)
    

    # 3. æ¨¡å‹å‰å‘ä¼ æ’­
    with torch.no_grad():
        outputs = model(**inputs)
        preds = outputs.logits.argmax(dim=-1).cpu().tolist()

    # 4. æ”¶é›†æ ‡ç­¾å’Œé¢„æµ‹
# æ”¶é›†æ ‡ç­¾å’Œé¢„æµ‹
    y_true.extend(batch_labels.detach().cpu().numpy().tolist())
y_pred.extend(preds)


print(">>> æ¨ç†å®Œæˆï¼Œå¼€å§‹è®¡ç®—å‡†ç¡®ç‡")

# åˆ†ç±»æŒ‡æ ‡è¾“å‡º
labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']
acc = accuracy_score(y_true, y_pred)
print(f"Accuracy: {acc * 100:.2f}%")
print(classification_report(y_true, y_pred, target_names=labels))


